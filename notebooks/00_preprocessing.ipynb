{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82773cc8-921c-47ca-978c-fff07d2119bd",
   "metadata": {},
   "source": [
    "## Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc31b508-040f-4f9d-b2aa-77aeec9d6af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.3.3\n",
      "Numpy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RAW_DATA_PATH = '../data/raw/rsd_15k.csv'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29bf29dd-056a-4b33-ae76-920d2d3e9d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 14613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No one understands how much I desperately want...</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>1648483701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Today I never wanted to live to see 25. That m...</td>\n",
       "      <td>Behavior</td>\n",
       "      <td>1651130449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Suicidal thoughts at / because of school For s...</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>1662712545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I feel like the pain will never end Everyday f...</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>1638628371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Is there even a point to living if you're not ...</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>1639749228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   users                                               text  sentiment  \\\n",
       "0      1  No one understands how much I desperately want...   Ideation   \n",
       "1      2  Today I never wanted to live to see 25. That m...   Behavior   \n",
       "2      3  Suicidal thoughts at / because of school For s...   Ideation   \n",
       "3      4  I feel like the pain will never end Everyday f...   Ideation   \n",
       "4      4  Is there even a point to living if you're not ...  Indicator   \n",
       "\n",
       "         time  \n",
       "0  1648483701  \n",
       "1  1651130449  \n",
       "2  1662712545  \n",
       "3  1638628371  \n",
       "4  1639749228  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\n",
    "        RAW_DATA_PATH, \n",
    "        quotechar='\"', \n",
    "        delimiter=',', \n",
    "    )\n",
    "    print(f\"count: {len(df)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"read error: {e}\")\n",
    "\n",
    "# check data is correct\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01f92d-1a18-4438-8939-05bfe39d4a01",
   "metadata": {},
   "source": [
    "## Text Cleaning & Time Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8770a7fa-21fb-45a5-a2ed-322e4e633dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label_ordinal</th>\n",
       "      <th>timestamp_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-28 16:08:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Behavior</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-04-28 07:20:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-09 08:35:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ideation</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-04 14:32:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Indicator</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-12-17 13:53:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   users  sentiment  label_ordinal        timestamp_dt\n",
       "0      1   Ideation              1 2022-03-28 16:08:21\n",
       "1      2   Behavior              2 2022-04-28 07:20:49\n",
       "2      3   Ideation              1 2022-09-09 08:35:45\n",
       "3      4   Ideation              1 2021-12-04 14:32:51\n",
       "4      4  Indicator              0 2021-12-17 13:53:48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Text Cleaning\n",
    "# remove '\\n' from the text to prevent errors during tokenization\n",
    "df['text'] = df['text'].astype(str).str.replace('\\n', ' ', regex=False).str.replace('\\r', '', regex=False)\n",
    "\n",
    "# 2. Timestamp Conversion (for approach 4)\n",
    "# from unix time to readable datetime\n",
    "df['timestamp_dt'] = pd.to_datetime(df['time'], unit='s')\n",
    "\n",
    "# 3. Label Encoding\n",
    "# follow our proposal and ref paper: Indicator < Ideation < Behavior < Attempt\n",
    "label_map = {\n",
    "    'Indicator': 0,\n",
    "    'Ideation': 1,\n",
    "    'Behavior': 2,\n",
    "    'Attempt': 3\n",
    "}\n",
    "\n",
    "df['label_ordinal'] = df['sentiment'].map(label_map)\n",
    "\n",
    "# remove data entries whose labels cannot be converted (if any)\n",
    "if df['label_ordinal'].isnull().sum() > 0:\n",
    "    n_missing = df['label_ordinal'].isnull().sum()\n",
    "    print(f\"remove {n_missing} data entries\")\n",
    "    df = df.dropna(subset=['label_ordinal'])\n",
    "\n",
    "df['label_ordinal'] = df['label_ordinal'].astype(int)\n",
    "\n",
    "# show results\n",
    "df[['users', 'sentiment', 'label_ordinal', 'timestamp_dt']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081a7ad3-7e79-46e5-9a30-060e07e7c292",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ae3a4c-7655-4a9c-89d7-c1280ced5569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Users: 1265\n",
      "Split results (number of users):\n",
      "Train Users: 1011 (79.9%)\n",
      "Val Users:   127 (10.0%)\n",
      "Test Users:  127 (10.0%)\n",
      "------------------------------\n",
      "Final dataset size (number of posts):\n",
      "Train Set: 11972 posts\n",
      "Val Set:   1605 posts\n",
      "Test Set:  1036 posts\n"
     ]
    }
   ],
   "source": [
    "# get all unique user id\n",
    "unique_users = df['users'].unique()\n",
    "n_users = len(unique_users)\n",
    "print(f\"Total Unique Users: {n_users}\")\n",
    "\n",
    "# ===== BEGIN: Gemini-generated block =====\n",
    "\n",
    "# 1. split out 10% as the test set (keeping 90%)\n",
    "train_val_users, test_users = train_test_split(unique_users, test_size=0.1, random_state=42)\n",
    "\n",
    "# 2. From the remaining 90%, split out another 10% of the overall data as the validation set\n",
    "# 1/9 of the remaining 90% is approximately 10% of the total dataset\n",
    "train_users, val_users = train_test_split(train_val_users, test_size=0.1111, random_state=42)\n",
    "\n",
    "print(f\"Split results (number of users):\")\n",
    "print(f\"Train Users: {len(train_users)} ({(len(train_users)/n_users)*100:.1f}%)\")\n",
    "print(f\"Val Users:   {len(val_users)} ({(len(val_users)/n_users)*100:.1f}%)\")\n",
    "print(f\"Test Users:  {len(test_users)} ({(len(test_users)/n_users)*100:.1f}%)\")\n",
    "\n",
    "# Split the original DataFrame based on User ID\n",
    "train_df = df[df['users'].isin(train_users)].copy()\n",
    "val_df = df[df['users'].isin(val_users)].copy()\n",
    "test_df = df[df['users'].isin(test_users)].copy()\n",
    "\n",
    "# reset index\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# ===== END: Gemini-generated block =====\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final dataset size (number of posts):\")\n",
    "print(f\"Train Set: {len(train_df)} posts\")\n",
    "print(f\"Val Set:   {len(val_df)} posts\")\n",
    "print(f\"Test Set:  {len(test_df)} posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98e824-8af9-47eb-93c0-ac3913fb6dcd",
   "metadata": {},
   "source": [
    "## Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4b3986-b7ab-473a-b1ea-184828561095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Check passed: No overlapping users between the Train Set and Test Set (No data leakage).\n"
     ]
    }
   ],
   "source": [
    "# Save in pickle format (keeps datetime and int data types for faster loading).\n",
    "train_path = os.path.join(PROCESSED_DIR, 'train.pkl')\n",
    "val_path = os.path.join(PROCESSED_DIR, 'val.pkl')\n",
    "test_path = os.path.join(PROCESSED_DIR, 'test.pkl')\n",
    "\n",
    "train_df.to_pickle(train_path)\n",
    "val_df.to_pickle(val_path)\n",
    "test_df.to_pickle(test_path)\n",
    "\n",
    "# ===== BEGIN: Gemini-generated block =====\n",
    "\n",
    "# Sanity Check: Check whether Train and Test have overlapping users (should be 0)\n",
    "overlap_users = set(train_df['users']) & set(test_df['users'])\n",
    "if len(overlap_users) == 0:\n",
    "    print(\"✅ Check passed: No overlapping users between the Train Set and Test Set (No data leakage).\")\n",
    "else:\n",
    "    print(f\"❌ Critical warning: Found {len(overlap_users)} overlapping users! Please check the data splitting logic.\")\n",
    "\n",
    "# ===== END: Gemini-generated block ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c974ba8-7c16-4c68-9416-05819eacb11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py311 env)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
