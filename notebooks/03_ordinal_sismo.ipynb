{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 1 — Load processed data and initialize runtime environment**\n",
        "This cell loads the preprocessed train/val/test splits, sets up the device (CUDA/MPS/CPU), and prepares global configurations such as batch sizes for training.\n"
      ],
      "metadata": {
        "id": "m_0-GqcOiRGL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "co8zq7xR1VC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863507a4-6832-4135-d226-49e46c30bebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for empath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \\\n",
        "  \"pandas>=2.0.0\" \\\n",
        "  \"numpy>=1.24.0\" \\\n",
        "  \"scikit-learn>=1.3.0\" \\\n",
        "  \"torch>=2.2.0\" \\\n",
        "  \"transformers>=4.36.0\" \\\n",
        "  \"xgboost>=2.0.0\" \\\n",
        "  \"matplotlib>=3.8.0\" \\\n",
        "  \"jupyter>=1.0.0\" \\\n",
        "  \"textblob>=0.17.1\" \\\n",
        "  \"empath>=0.89\" \\\n",
        "  \"sentencepiece>=0.1.99\" \\\n",
        "  \"accelerate>=0.25.0\" \\\n",
        "  \"protobuf>=4.25.0\" \\\n",
        "  \"tqdm>=4.66.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/becoollll/Suicide-Risk-Detection.git\n",
        "%cd Suicide-Risk-Detection\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPDZPHZ41_4F",
        "outputId": "0ecdf424-27ca-466e-abd8-29601780a7c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Suicide-Risk-Detection'...\n",
            "remote: Enumerating objects: 77, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (53/53), done.\u001b[K\n",
            "remote: Total 77 (delta 30), reused 60 (delta 21), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (77/77), 71.58 KiB | 4.47 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n",
            "/content/Suicide-Risk-Detection\n",
            "notebooks  README.md  requirements.txt\tsrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"microsoft/deberta-v3-base\"   # Backbone model\n",
        "MAX_LEN = 512                                # Tokenization max length\n",
        "BATCH_SIZE = 32                               # Training batch size\n",
        "EPOCHS = 4                                    # Number of training epochs\n",
        "LEARNING_RATE = 2e-5                          # LR\n",
        "NUM_CLASSES = 4                               # (Indicator, Ideation, Behavior, Attempt)\n",
        "\n",
        "print(\"MODEL_NAME    :\", MODEL_NAME)\n",
        "print(\"MAX_LEN       :\", MAX_LEN)\n",
        "print(\"BATCH_SIZE    :\", BATCH_SIZE)\n",
        "print(\"EPOCHS        :\", EPOCHS)\n",
        "print(\"LEARNING_RATE :\", LEARNING_RATE)\n",
        "print(\"NUM_CLASSES   :\", NUM_CLASSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1EK5d5U2Ghf",
        "outputId": "02663fea-df1e-47b7-f26a-fb7633a3f3f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL_NAME    : microsoft/deberta-v3-base\n",
            "MAX_LEN       : 512\n",
            "BATCH_SIZE    : 32\n",
            "EPOCHS        : 4\n",
            "LEARNING_RATE : 2e-05\n",
            "NUM_CLASSES   : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 1: Imports & Load Processed Data =====\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# ---- Project paths  ----\n",
        "PROJECT_ROOT = \"/content/Suicide-Risk-Detection\"\n",
        "sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "from src.utils import compute_graded_metrics\n",
        "from src.loss import OrdinalLoss\n",
        "\n",
        "PROCESSED_DATA_DIR = f\"{PROJECT_ROOT}/data/processed\"\n",
        "print(\"PROCESSED_DATA_DIR:\", PROCESSED_DATA_DIR)\n",
        "\n",
        "train_df = pd.read_pickle(os.path.join(PROCESSED_DATA_DIR, \"train.pkl\"))\n",
        "val_df   = pd.read_pickle(os.path.join(PROCESSED_DATA_DIR, \"val.pkl\"))\n",
        "test_df  = pd.read_pickle(os.path.join(PROCESSED_DATA_DIR, \"test.pkl\"))\n",
        "\n",
        "print(f\"Train, Val, Test size: {len(train_df)}, {len(val_df)}, {len(test_df)}\")\n",
        "display(train_df.head())\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    print(\"Using device: CUDA (GPU)\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "    print(\"Using device: MPS (Apple Silicon GPU)\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"Using device: CPU\")\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "MICRO_BATCH_SIZE = 16\n",
        "ACCUM_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\n",
        "\n",
        "print(f\"Effective batch size = {MICRO_BATCH_SIZE} x {ACCUM_STEPS} = {BATCH_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "EQ_zmH_e2Go0",
        "outputId": "912e54bc-1793-4950-ca9c-6587327c3049"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROCESSED_DATA_DIR: /content/Suicide-Risk-Detection/data/processed\n",
            "Train, Val, Test size: 11972, 1605, 1036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   users                                               text  sentiment  \\\n",
              "0      1  No one understands how much I desperately want...   Ideation   \n",
              "1      2  Today I never wanted to live to see 25. That m...   Behavior   \n",
              "2      3  Suicidal thoughts at / because of school For s...   Ideation   \n",
              "3      4  I feel like the pain will never end Everyday f...   Ideation   \n",
              "4      4  Is there even a point to living if you're not ...  Indicator   \n",
              "\n",
              "         time        timestamp_dt  label_ordinal  \n",
              "0  1648483701 2022-03-28 16:08:21              1  \n",
              "1  1651130449 2022-04-28 07:20:49              2  \n",
              "2  1662712545 2022-09-09 08:35:45              1  \n",
              "3  1638628371 2021-12-04 14:32:51              1  \n",
              "4  1639749228 2021-12-17 13:53:48              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-902df5dd-0e19-43b2-bdee-812ff551a6c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>users</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>time</th>\n",
              "      <th>timestamp_dt</th>\n",
              "      <th>label_ordinal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>No one understands how much I desperately want...</td>\n",
              "      <td>Ideation</td>\n",
              "      <td>1648483701</td>\n",
              "      <td>2022-03-28 16:08:21</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Today I never wanted to live to see 25. That m...</td>\n",
              "      <td>Behavior</td>\n",
              "      <td>1651130449</td>\n",
              "      <td>2022-04-28 07:20:49</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Suicidal thoughts at / because of school For s...</td>\n",
              "      <td>Ideation</td>\n",
              "      <td>1662712545</td>\n",
              "      <td>2022-09-09 08:35:45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>I feel like the pain will never end Everyday f...</td>\n",
              "      <td>Ideation</td>\n",
              "      <td>1638628371</td>\n",
              "      <td>2021-12-04 14:32:51</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Is there even a point to living if you're not ...</td>\n",
              "      <td>Indicator</td>\n",
              "      <td>1639749228</td>\n",
              "      <td>2021-12-17 13:53:48</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-902df5dd-0e19-43b2-bdee-812ff551a6c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-902df5dd-0e19-43b2-bdee-812ff551a6c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-902df5dd-0e19-43b2-bdee-812ff551a6c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-71bbf343-9012-46b9-ac2e-db783b106c3d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71bbf343-9012-46b9-ac2e-db783b106c3d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-71bbf343-9012-46b9-ac2e-db783b106c3d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"Effective batch size = {MICRO_BATCH_SIZE} x {ACCUM_STEPS} = {BATCH_SIZE}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"users\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Today I never wanted to live to see 25. That means it has to be today. I miss you dad. I miss you grandpa. I\\u2019m sorry.\",\n          \"Is there even a point to living if you're not living for anything? \",\n          \"Suicidal thoughts at / because of school For some background, im 14f who is in secondary school, and I\\u2019m having problems with quite ALOT of people in my school, but mainly a boy who I\\u2019ll call troy. I was first put in the same form as him in year 8, but nothing too serious happened until about 2021. I remember the first big incident was when we were in RE and he kept accusing me of stealing a glue stick and knocking my water bottle off my desk repeatedly (while someone else was laughing) and after that it was too many incidents that I could count. And the fact that he is EXTREMELY popular doesn\\u2019t fucking help. Because now I think everyone just likes to bully me for fun. I remember our form having a quiz close to Christmas, and Troy (&amp; a few others) were throwing a water bottle across the room. I threw it back &amp; the teacher asked who it was. THE WHOLE CLASS said it was me and the teacher told ME off for it. Anyways Troy bullied me for it, and a few people made fun of me for crying (which I was trying my hardest not to) And i remember going home (more times i can count) Crying and thinking of killing myself. As a result of this, I also have a low self esteem. I told the headteacher about it and he had a few talks with him, otherwise he did nothing. And people just say \\u201cjust ignore them\\u201d WHICH I HAVE TRIED, and let me tell you, IT DOESNT FUCKING HELP.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Ideation\",\n          \"Behavior\",\n          \"Indicator\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9776197,\n        \"min\": 1638628371,\n        \"max\": 1662712545,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1651130449,\n          1639749228,\n          1662712545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_dt\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2021-12-04 14:32:51\",\n        \"max\": \"2022-09-09 08:35:45\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2022-04-28 07:20:49\",\n          \"2021-12-17 13:53:48\",\n          \"2022-09-09 08:35:45\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_ordinal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: CUDA (GPU)\n",
            "Effective batch size = 16 x 2 = 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 2 — Build tokenizer, dataset class, and dataloaders**\n",
        "This cell initializes the tokenizer, defines the dataset class for RSD inputs, and constructs DataLoaders used during training and evaluation."
      ],
      "metadata": {
        "id": "ZJ8-aOvDiXsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Cell 2: Tokenizer, Dataset & DataLoaders =====\n",
        "\n",
        "TEXT_COL = \"text\"\n",
        "LABEL_COL = \"label_ordinal\"\n",
        "\n",
        "label2id = {\n",
        "    \"Indicator\": 0,\n",
        "    \"Ideation\": 1,\n",
        "    \"Behavior\": 2,\n",
        "    \"Attempt\": 3,\n",
        "}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class RSDDataset(Dataset):\n",
        "    def __init__(self, df, text_col, label_col):\n",
        "        self.texts = df[text_col].tolist()\n",
        "        self.labels = df[label_col].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = int(self.labels[idx])\n",
        "\n",
        "        enc = tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    RSDDataset(train_df, TEXT_COL, LABEL_COL),\n",
        "    batch_size=MICRO_BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    RSDDataset(val_df, TEXT_COL, LABEL_COL),\n",
        "    batch_size=MICRO_BATCH_SIZE * 2,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    RSDDataset(test_df, TEXT_COL, LABEL_COL),\n",
        "    batch_size=MICRO_BATCH_SIZE * 2,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "print(\"Batch input_ids shape     :\", batch[\"input_ids\"].shape)\n",
        "print(\"Batch attention_mask shape:\", batch[\"attention_mask\"].shape)\n",
        "print(\"Batch labels shape        :\", batch[\"label\"].shape)"
      ],
      "metadata": {
        "id": "114ZNV5z2Grn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd70e93-be6b-43a4-f454-78bf33e1c9b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch input_ids shape     : torch.Size([16, 512])\n",
            "Batch attention_mask shape: torch.Size([16, 512])\n",
            "Batch labels shape        : torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 3 — Define the SISMO Ordinal Model with DeBERTa backbone**\n",
        "This cell creates the full fine-tuning model architecture: a DeBERTa backbone and a BiLSTM classification head for ordinal prediction."
      ],
      "metadata": {
        "id": "k_OlwEy-il0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SISMOOrdinalModel(nn.Module):\n",
        "    def __init__(self, num_classes=NUM_CLASSES):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = AutoModel.from_pretrained(MODEL_NAME)\n",
        "\n",
        "        # Important for DeBERTa v3\n",
        "        if hasattr(self.backbone.config, \"use_cache\"):\n",
        "            self.backbone.config.use_cache = False\n",
        "\n",
        "        print(\"Backbone UNFROZEN: full fine-tuning (no gradient checkpointing).\")\n",
        "\n",
        "        hidden_size = self.backbone.config.hidden_size\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=256,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(256 * 2, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        seq_output = outputs.last_hidden_state  # (B, T, H)\n",
        "\n",
        "        lstm_out, (h_n, _) = self.lstm(seq_output)  # h_n: (2, B, 256)\n",
        "        h_forward = h_n[-2]\n",
        "        h_backward = h_n[-1]\n",
        "        pooled = torch.cat([h_forward, h_backward], dim=-1)\n",
        "\n",
        "        logits = self.classifier(self.dropout(pooled))\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = SISMOOrdinalModel().to(DEVICE)\n",
        "\n",
        "print(\"Model initialized on\", DEVICE)"
      ],
      "metadata": {
        "id": "F1Ep-NdC2GuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509940e6-447e-440e-f75e-199fa9f9f4c8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backbone UNFROZEN: full fine-tuning (no gradient checkpointing).\n",
            "Model initialized on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 4 — Configure loss function, optimizer, and scheduler**\n",
        "This cell initializes the OrdinalLoss, sets class weights, and prepares AdamW and learning-rate warmup scheduling."
      ],
      "metadata": {
        "id": "w1ejnGEhioUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_RATIO = 0.1\n",
        "\n",
        "support_counts = torch.tensor([305, 530, 135, 66], dtype=torch.float32)\n",
        "print(\"Support counts:\", support_counts.tolist())\n",
        "\n",
        "raw_weights = 1.0 / torch.log(support_counts + 1.0)\n",
        "class_weights = raw_weights / raw_weights.sum() * len(support_counts)\n",
        "\n",
        "print(\"Class weights:\", class_weights.tolist())\n",
        "\n",
        "criterion = OrdinalLoss(\n",
        "    alpha=2.0,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    device=DEVICE,\n",
        ").to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "total_steps = (len(train_loader) // ACCUM_STEPS) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=int(total_steps * WARMUP_RATIO),\n",
        "    num_training_steps=total_steps,\n",
        ")\n",
        "\n",
        "print(f\"EPOCHS={EPOCHS} | total_steps={total_steps}\")"
      ],
      "metadata": {
        "id": "KQl3J0Th2Gxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e094b37d-335f-410e-ce61-806b2e2575ea"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support counts: [305.0, 530.0, 135.0, 66.0]\n",
            "Class weights: [0.9012120962142944, 0.8220493197441101, 1.049974799156189, 1.2267636060714722]\n",
            "EPOCHS=4 | total_steps=1496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 5 — Training loop with gradient accumulation**\n",
        "This cell defines the core training function that performs gradient accumulation to simulate a larger effective batch size."
      ],
      "metadata": {
        "id": "6nSYl-UGivC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, data_loader, optimizer, criterion, device, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    accum_counter = 0\n",
        "\n",
        "    for step, batch in enumerate(data_loader):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        raw_loss = criterion(logits, labels)\n",
        "\n",
        "        loss = raw_loss / ACCUM_STEPS\n",
        "        loss.backward()\n",
        "        accum_counter += 1\n",
        "\n",
        "        bs = input_ids.size(0)\n",
        "        total_loss += raw_loss.item() * bs\n",
        "        total_examples += bs\n",
        "\n",
        "        if accum_counter == ACCUM_STEPS:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "            accum_counter = 0\n",
        "\n",
        "        if (step + 1) % (ACCUM_STEPS * 10) == 0:\n",
        "            print(f\"  step {step+1} | loss={raw_loss.item():.4f}\")\n",
        "\n",
        "    if accum_counter > 0:\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "    avg_loss = total_loss / total_examples\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "JRA78c234UUQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 6 — Evaluation: compute accuracy, graded precision/recall/F1**\n",
        "This cell implements the evaluation function used during validation to compute model performance using graded metrics."
      ],
      "metadata": {
        "id": "KhX7GjpLixqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "            all_preds.extend(preds.cpu().tolist())\n",
        "\n",
        "    metrics = compute_graded_metrics(all_labels, all_preds)\n",
        "    gp = metrics[\"graded_precision\"]\n",
        "    gr = metrics[\"graded_recall\"]\n",
        "    gf1 = metrics[\"graded_f1\"]\n",
        "\n",
        "    acc = (torch.tensor(all_labels) == torch.tensor(all_preds)).float().mean().item()\n",
        "\n",
        "    return acc, gp, gr, gf1"
      ],
      "metadata": {
        "id": "C3oPIlrdWM3G"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cell 7 — Execute training and track best GF1 performance**\n",
        "This cell runs the full training process for all epochs, reports validation metrics, and saves the best performing model checkpoint."
      ],
      "metadata": {
        "id": "nfe1apveizlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_gf1 = 0.0\n",
        "\n",
        "print(\"===== Start Training =====\")\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
        "    train_loss = train_one_epoch(\n",
        "        model,\n",
        "        train_loader,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        DEVICE,\n",
        "        scheduler,\n",
        "    )\n",
        "\n",
        "    val_acc, val_gp, val_gr, val_gf1 = evaluate(model, val_loader, DEVICE)\n",
        "\n",
        "    print(\n",
        "        f\"[Epoch {epoch}] \"\n",
        "        f\"train_loss={train_loss:.4f} | \"\n",
        "        f\"val_acc={val_acc:.4f} | \"\n",
        "        f\"GP={val_gp:.4f} | GR={val_gr:.4f} | GF1={val_gf1:.4f}\"\n",
        "    )\n",
        "\n",
        "    if val_gf1 > best_val_gf1:\n",
        "        best_val_gf1 = val_gf1\n",
        "        torch.save(model.state_dict(), \"best_sismo_ordinal.pt\")\n",
        "        print(\"  -> Best model updated and saved.\")\n",
        "\n",
        "print(\"\\nBest Val Graded F1:\", best_val_gf1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sFsb67n4UW2",
        "outputId": "77cce4a8-a8fb-4995-a5cb-0147a293fa81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start Training =====\n",
            "\n",
            "Epoch 1/4\n",
            "  step 20 | loss=0.9795\n",
            "  step 40 | loss=0.9640\n",
            "  step 60 | loss=1.0996\n",
            "  step 80 | loss=0.8561\n",
            "  step 100 | loss=0.8347\n",
            "  step 120 | loss=1.1354\n",
            "  step 140 | loss=0.8741\n",
            "  step 160 | loss=1.2059\n",
            "  step 180 | loss=0.8301\n",
            "  step 200 | loss=0.9039\n",
            "  step 220 | loss=0.8500\n",
            "  step 240 | loss=0.7761\n",
            "  step 260 | loss=0.8540\n",
            "  step 280 | loss=1.0414\n",
            "  step 300 | loss=0.8324\n",
            "  step 320 | loss=0.8120\n",
            "  step 340 | loss=0.9649\n",
            "  step 360 | loss=0.8822\n",
            "  step 380 | loss=0.9831\n",
            "  step 400 | loss=0.7871\n",
            "  step 420 | loss=1.0070\n",
            "  step 440 | loss=1.2223\n",
            "  step 460 | loss=0.8004\n",
            "  step 480 | loss=0.8801\n",
            "  step 500 | loss=0.9960\n",
            "  step 520 | loss=0.7567\n",
            "  step 540 | loss=1.0620\n",
            "  step 560 | loss=1.0036\n",
            "  step 580 | loss=0.8796\n",
            "  step 600 | loss=0.7616\n",
            "  step 620 | loss=1.0768\n",
            "  step 640 | loss=0.9033\n",
            "  step 660 | loss=0.9235\n",
            "  step 680 | loss=0.8577\n",
            "  step 700 | loss=0.8207\n",
            "  step 720 | loss=0.9005\n",
            "  step 740 | loss=0.9409\n",
            "[Epoch 1] train_loss=0.9354 | val_acc=0.7290 | GP=0.8193 | GR=0.9097 | GF1=0.8621\n",
            "  -> Best model updated and saved.\n",
            "\n",
            "Epoch 2/4\n",
            "  step 20 | loss=0.7460\n",
            "  step 40 | loss=0.7583\n",
            "  step 60 | loss=0.9545\n",
            "  step 80 | loss=0.8832\n",
            "  step 100 | loss=0.8063\n",
            "  step 120 | loss=0.9272\n",
            "  step 140 | loss=0.9217\n",
            "  step 160 | loss=0.6991\n",
            "  step 180 | loss=0.9027\n",
            "  step 200 | loss=0.8537\n",
            "  step 220 | loss=1.0504\n",
            "  step 240 | loss=0.8364\n",
            "  step 260 | loss=1.0174\n",
            "  step 280 | loss=0.9398\n",
            "  step 300 | loss=0.8221\n",
            "  step 320 | loss=0.8671\n",
            "  step 340 | loss=1.2134\n",
            "  step 360 | loss=0.7151\n",
            "  step 380 | loss=0.8877\n",
            "  step 400 | loss=0.8285\n",
            "  step 420 | loss=0.7388\n",
            "  step 440 | loss=0.8689\n",
            "  step 460 | loss=0.9404\n",
            "  step 480 | loss=0.9554\n",
            "  step 500 | loss=0.7626\n",
            "  step 520 | loss=0.8609\n",
            "  step 540 | loss=0.9132\n",
            "  step 560 | loss=0.9525\n",
            "  step 580 | loss=0.7490\n",
            "  step 600 | loss=0.9412\n",
            "  step 620 | loss=0.7441\n",
            "  step 640 | loss=0.8246\n",
            "  step 660 | loss=0.9062\n",
            "  step 680 | loss=0.8085\n",
            "  step 700 | loss=0.9949\n",
            "  step 720 | loss=0.8486\n",
            "  step 740 | loss=0.7382\n",
            "[Epoch 2] train_loss=0.8711 | val_acc=0.7526 | GP=0.8642 | GR=0.8885 | GF1=0.8762\n",
            "  -> Best model updated and saved.\n",
            "\n",
            "Epoch 3/4\n",
            "  step 20 | loss=1.0256\n",
            "  step 40 | loss=0.8543\n",
            "  step 60 | loss=0.9612\n",
            "  step 80 | loss=0.8261\n",
            "  step 100 | loss=0.7447\n",
            "  step 120 | loss=0.7463\n",
            "  step 140 | loss=0.7980\n",
            "  step 160 | loss=0.8311\n",
            "  step 180 | loss=0.7608\n",
            "  step 200 | loss=0.6708\n",
            "  step 220 | loss=0.7530\n",
            "  step 240 | loss=1.0757\n",
            "  step 260 | loss=0.9508\n",
            "  step 280 | loss=0.7502\n",
            "  step 300 | loss=0.7077\n",
            "  step 320 | loss=0.6981\n",
            "  step 340 | loss=0.8205\n",
            "  step 360 | loss=0.7863\n",
            "  step 380 | loss=0.8393\n",
            "  step 400 | loss=0.7279\n",
            "  step 420 | loss=0.8661\n",
            "  step 440 | loss=0.8485\n",
            "  step 460 | loss=0.6536\n",
            "  step 480 | loss=0.6192\n",
            "  step 500 | loss=0.8797\n",
            "  step 520 | loss=0.7609\n",
            "  step 540 | loss=0.7321\n",
            "  step 560 | loss=0.8217\n",
            "  step 580 | loss=0.6725\n",
            "  step 600 | loss=0.8800\n",
            "  step 620 | loss=0.7170\n",
            "  step 640 | loss=0.8582\n",
            "  step 660 | loss=0.9147\n",
            "  step 680 | loss=0.9362\n",
            "  step 700 | loss=0.8627\n",
            "  step 720 | loss=0.8533\n",
            "  step 740 | loss=0.9175\n",
            "[Epoch 3] train_loss=0.8303 | val_acc=0.7489 | GP=0.8692 | GR=0.8798 | GF1=0.8744\n",
            "\n",
            "Epoch 4/4\n",
            "  step 20 | loss=0.7883\n",
            "  step 40 | loss=0.9079\n",
            "  step 60 | loss=0.8713\n",
            "  step 80 | loss=0.8092\n",
            "  step 100 | loss=0.7767\n",
            "  step 120 | loss=0.8097\n",
            "  step 140 | loss=0.9102\n",
            "  step 160 | loss=0.7638\n",
            "  step 180 | loss=0.9527\n",
            "  step 200 | loss=0.7994\n",
            "  step 220 | loss=0.8489\n",
            "  step 240 | loss=0.9498\n",
            "  step 260 | loss=0.8546\n",
            "  step 280 | loss=0.7540\n",
            "  step 300 | loss=0.6427\n",
            "  step 320 | loss=0.7149\n",
            "  step 340 | loss=0.8249\n",
            "  step 360 | loss=0.8054\n",
            "  step 380 | loss=0.7846\n",
            "  step 400 | loss=0.7194\n",
            "  step 420 | loss=0.7993\n",
            "  step 440 | loss=0.8289\n",
            "  step 460 | loss=0.7855\n",
            "  step 480 | loss=0.8440\n",
            "  step 500 | loss=0.7209\n",
            "  step 520 | loss=0.8194\n",
            "  step 540 | loss=0.7943\n",
            "  step 560 | loss=0.7990\n",
            "  step 580 | loss=0.8369\n",
            "  step 600 | loss=0.8085\n",
            "  step 620 | loss=0.6543\n",
            "  step 640 | loss=0.9885\n",
            "  step 660 | loss=0.7315\n",
            "  step 680 | loss=0.8889\n",
            "  step 700 | loss=0.9295\n",
            "  step 720 | loss=0.8041\n",
            "  step 740 | loss=0.9757\n",
            "[Epoch 4] train_loss=0.8148 | val_acc=0.7489 | GP=0.8692 | GR=0.8798 | GF1=0.8744\n",
            "\n",
            "Best Val Graded F1: 0.8762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== BEGIN: Gemini-generated block =====\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "model_to_eval = model\n",
        "\n",
        "model_to_eval.eval()\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "\n",
        "        logits_adj = logits.clone()\n",
        "\n",
        "        logits_adj[:, 2] += 0.2\n",
        "        logits_adj[:, 3] += 0.4\n",
        "\n",
        "        preds = torch.argmax(logits_adj, dim=1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().tolist())\n",
        "        all_preds.extend(preds.cpu().tolist())\n",
        "\n",
        "y_test = all_labels\n",
        "y_pred = all_preds\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nSimple Accuracy: {acc:.4f}\")\n",
        "# ===== END: Gemini-generated block =====\n",
        "\n",
        "target_names = ['Indicator', 'Ideation', 'Behavior', 'Attempt']\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "graded_metrics = compute_graded_metrics(y_test, y_pred)\n",
        "print(\"\\n=== Graded Metrics ===\")\n",
        "print(f\"Graded Precision: {graded_metrics['graded_precision']:.4f}\")\n",
        "print(f\"Graded Recall:    {graded_metrics['graded_recall']:.4f}\")\n",
        "print(f\"Graded F1-Score:  {graded_metrics['graded_f1']:.4f}\")"
      ],
      "metadata": {
        "id": "lTXnHUZL2GzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb7707c-8fc6-4a5d-fe0d-39f15d9b5c6c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Simple Accuracy: 0.7143\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Indicator       0.74      0.74      0.74       305\n",
            "    Ideation       0.77      0.74      0.75       530\n",
            "    Behavior       0.55      0.66      0.60       135\n",
            "     Attempt       0.59      0.55      0.57        66\n",
            "\n",
            "    accuracy                           0.71      1036\n",
            "   macro avg       0.66      0.67      0.66      1036\n",
            "weighted avg       0.72      0.71      0.72      1036\n",
            "\n",
            "\n",
            "=== Graded Metrics ===\n",
            "Graded Precision: 0.8542\n",
            "Graded Recall:    0.8600\n",
            "Graded F1-Score:  0.8571\n"
          ]
        }
      ]
    }
  ]
}